\documentclass{article}
\usepackage[utf8]{amsmath}
\usepackage{flexisym}

\begin{document}

These are my notes on Section 2.7 from Abbott. I will provide proofs to various theorems on infinite series as well as provide my responses to any problems of interest. \\

(a) Prove the alternating series test by showing that $(a_n)$ is a Cauchy sequence. \\

Since we are looking to show the Cauchy Criterion, let us look at the sequence of partial sums. 

\begin{equation}
    |s_n - s_m| = |a_{m+1} + a_{m+2} + ... + a_n|
\end{equation}

Since the sign of each term is alternating by our hypothesis, and $(a_n)$ is decreasing, we can assert that 

\begin{equation}
    |s_n - s_m| = |a_{m+1} + a_{m+2} + ... + a_n| < |a_{m+1}|
\end{equation}

Since we know that $a_n \rightarrow 0$, for all n $\ge$ N, $|a_n| < \epsilon$. Therefore, for all $n, m \ge N$,

\begin{equation}
    |s_n - s_m| < \epsilon
\end{equation}

The sequence of partial sums is Cauchy, thus the series is convergent. \\

(b) Supply another proof using the Nested Interval Property. \\

Construct nested intervals in the following manner: $I_n = [s_n, s_n+1]$. By our hypothesis, we know that these intervals are nested. In addition, since $(a_n) \rightarrow 0$, for all $n \ge N$, the length of every interval $I_n$ is less than some $\epsilon$. By the Nested Interval Property, ${\bigcap}_{n=1}^\infty I_n \neq \emptyset$. Thus, we can propose some x that is contained in every $I_n$ to be the limit point of the series, since every $s_n$ for all $n \ge N$ becomes arbitrarily close to this limit point. \\

(c) Consider the subsequences $(s_{2n})$ and $(s_{2n+1})$ and show how the Monotone Convergence Theorem leads to a third proof. \\

Take note that the partial sums $(s_{2n})$ and $(s_{2n+1})$ end in even and odd values respectively. Without loss of generality, let us assume that $a_n > 0$. We can then assert that every even term in the series is less than zero, and every odd term is greater than zero. We will now show that the sequence of partial sums $(s_{2n})$ and $(s_{2n+1})$ are monotone increasing and decreasing respectively. Let us take a look at $s_{2n+2}$ and $s_{2n}$. 

\begin{equation}
    s_{2n+2} - s_{2n} = a_{2n+1} + a_{2n+2} > 0
\end{equation}

Since $a_{2n+1} > 0$, $(a_n)$ is decreasing, and $a_{2n+2} < 0$, we have shown that the sequence $(s_{2n})$ is monotone increasing. It is very similar to show that $(s_{2n+1})$ is monotone decreasing. In addition, each partial sum $s_{2n}$ is bounded above by $|s_{2n-1}|$. Similarly, $s_{2n+1}$ is bounded below by $s_{2n}$. By the Monotone Convergence Theorem, both sequences converge to limits $L_1$ and $L_2$ respectively. In addition, since $(a_n) \rightarrow 0$, 

\begin{equation}
    |s_{2n} - s_{2n+1}| < \epsilon / 3
\end{equation}

If we could show that $(s_{2n})$ and $(s_{2n+1})$ converged to the same limit, we will have shown that the series itself converges. Putting this all together yields 

\begin{equation}
\begin{split}
    |L_1 - L_2| & = | (L_1 - s_{2n}) + (s_{2n} - s_{2n+1}) + (s_{2n+1} - L_2) | \\ 
    & \leq |L_1 - s_{2n}| + |s_{2n} - s_{2n+1}| + |s_{2n+1} - L_2| \\
    & = \epsilon / 3 +  \epsilon / 3 +  \epsilon / 3  \\
    & = \epsilon
\end{split}
\end{equation}

Let us say that for $(s_{2n})$, all terms are in within $\epsilon$ of $L_1$ for all $n \ge N_1$, and for $(s_{2n+1})$, all terms are within $\epsilon$ of $L_2$ for all $n \ge N_2$. Again, say that $|a_n| < \epsilon$ for all $n \ge N_3$. Setting $N = \max \{\,N_1, N_2, N_3\}\ $satisfies the above equation. Thus, merging these two subsequences back together yields a sequence of partial sums that converge, and the statement is proven. \\

I will now give my attempt to prove a theorem from Section 2.4. \\

$Theorem: \sum_{n=1}^{\infty} 1/n^p$ converges if and only if $p > 1$. \\

To prove one direction, we will use the contrapositive. Assume $p \ge 1$. We will now show that the sequence $\sum_{n=1}^{\infty} 1/n^p$ diverges. Thankfully, we know that the harmonic series diverges, thus we can use the Comparison Test. Since $p \ge 1$, $ 1/n^p \ge 1/n$ for all $n \in \mathbb{N}$. Thus, by the Comparison Test, $\sum_{n=1}^{\infty} 1/n^p$ diverges. \\

To prove the reverse direction, we must use some facts about geometric series. Assume $p > 1$. Recall the Cauchy Condensation Test. If $\sum_{n=0}^{\infty} 2^n/(2^n)^p$ converges, then $\sum_{n=1}^{\infty} 1/n^p$ converges as well. With some simplification, the series becomes

\begin{equation}
    \sum_{n=0}^{\infty} \frac{2^n}{(2^n)^p} = \sum_{n=0}^{\infty} \frac{1}{(2^n)^{p-1}} = \sum_{n=0}^{\infty} (\frac{1}{2^{p-1}})^n
\end{equation}

Note that this is a geometric series. Since $p > 1$, $1/2^{p-1} < 1$. Thus, this is a geometric series, and the series $\sum_{n=1}^{\infty} 1/n^p$ converges. 

\newpage

Various tests for the convergence of series are given. I will provide my attempts at proofs of their correctness here. \\

$Thereom:$ Given a series $\sum_{n=1}^{\infty} a_n$ with $a_n \neq 0$, the Ratio Test states that if $(a_n)$ satisfies 

\begin{equation}
    \lim_{n\to\infty} \bigg|\frac{a_{n+1}}{a_n}\bigg| = r < 1
\end{equation}

then the series converges absolutely. \\

Let $a\textprime$ satisfy $r < r\textprime < 1$. We can guarantee such a $r\textprime$ exists by the density of $\mathbb{Q}$ in $\mathbb{R}$. Also, by our definition of convergence, we can rewrite the above limit, arguing that for all $n \geq N$, 

\begin{equation}
    \bigg|\bigg|\frac{a_{n+1}}{a_n}\bigg| - r\bigg| < \epsilon
\end{equation}


We can rewrite this inequality as

\begin{equation}
    r - \epsilon <\bigg|\frac{a_{n+1}}{a_n}\bigg| < \epsilon + r
\end{equation}


Multiplying each side of the inequality by $|a_n|$ yields

\begin{equation}
    |a_n|(r-\epsilon) < |a_{n+1}| < |a_n|(r+\epsilon)
\end{equation}

Fix $\epsilon$ to be small enough so that $r+\epsilon < r\textprime$. It follows that 

\begin{equation}
    |a_{n+1}| < |a_n|r\textprime
\end{equation}

Note that this holds for all $n \geq N$. Now, consider the series $|a_N|\sum (r\textprime)^n$. Because $r\textprime < 1$, this is a geometric series, which we have already shown converges. Now, recall the above inequality. 

\begin{equation}
\begin{split}
    & |a_{N+1}| < |a_N|r\textprime \\
    & |a_{N+2}| < |a_N|(r\textprime)^2 \\
    & |a_{N+3}| < |a_N|(r\textprime)^3 \\
    & \hspace{11 mm} \vdots
\end{split}
\end{equation}

With this inductive argument, the Comparison Test implies that $\sum |a_n|$ converges. \\

\newpage

Below is a nice tool for working with series. \\

Let $(x_n)$ and $(y_n)$ be sequences, and let $s_n = x_1 + x_2 + \dots + x_n$. Use the observation that $x_j = s_j - s_{j-1}$ to verify the formula

\begin{equation}
    \sum_{j=m+1}^{n} x_j y_j = s_n y_{n+1} - s_m y_{m+1} + \sum_{j=m+1}^{n} s_j(y_{j} - y_{j+1})
\end{equation}

Let us expand out the summation $\sum_{j=m+1}^{n} s_j(y_{j+1} - y_j)$ from the right side of this formula. 

\begin{equation}
\begin{split}
    & \hspace{5 mm} s_{m+1}(y_{m+1} - y_{m+2}) + s_{m+2}(y_{m+2} - y_{m+3}) + \dots + s_{n}(y_{n} - y_{n+1}) \\[15pt]
    & = s_{m+1}y_{m+1} + y_{m+2}(s_{m+2} - s_{m+1}) + \dots + y_n(s_{n} - s_{n-1}) - s_n y_{n+1} \\[15pt]
    & = s_{m+1}y_{m+1} + y_{m+2}x_{m+2} + \dots + y_n x_n - s_n y_{n+1} \\[10pt]
    & = s_{m+1}y_{m+1} - s_n y_{n+1} + \sum_{j=m+2}^{n} x_j y_j
\end{split}
\end{equation}

Adding this back to the rest of the right-hand side of the equation yields

\begin{equation}
\begin{split}
    & \hspace{5 mm} s_n y_{n+1} - s_m y_{m+1} + s_{m+1}y_{m+1} - s_n y_{n+1} + \sum_{j=m+2}^{n} x_j y_j \\
    &= y_{m+1}(s_{m+1} - s_m) + ( s_n y_{n+1} - s_n y_{n+1}) + \sum_{j=m+2}^{n} x_j y_j \\
    &= x_{m+1} y_{m+1} + \sum_{j=m+2}^{n} x_j y_j \\
    &= \sum_{j=m+1}^{n} x_j y_j
\end{split}
\end{equation}

Thus, the right-hand side equals the left hand side as desired. This lemma will come in handy for the next proof. 
\newpage

Dirichlet's Test for convergence states that if the partial sums of $\sum_{n=1}^{\infty} x_n$ are bounded (but not necessarily convergent),
and if $(y_n)$ is a sequence satisfying $y_1 \geq y_2 \geq y_3 \geq \dots \geq 0$ with $\lim_{n\to \infty} y_n = 0$,
then the series $\sum_{n=1}^{\infty} x_n y_n$ converges. \\

Let $M > 0$ be a bound on the partial sums of $\sum_{n=1}^{\infty} x_n$. Then, 

\begin{equation}
\begin{split}
    &\hspace{-20 mm}\Bigg|\sum_{j=m+1}^{n} x_j y_j \Bigg| = \Bigg| s_n y_{n+1} - s_m y_{m+1} + \sum_{j=m+1}^{n} s_j(y_{j} - y_{j+1})\Bigg| \\
    &\leq | s_n y_{n+1} - s_m y_{m+1} + \sum_{j=m+1}^{n} M(y_{j} - y_{j+1}) | \\
    &= | M y_{n+1} - s_m y_{m+1} + M y_{m+1} - M y_{n+1} | \\[10 pt]
    &\leq | (M - s_m) y_{m+1} |
\end{split}
\end{equation}

Since $M$ is a bound on the partial sums $s_n$, $M - s_m$ is at most $2M$. This gives us the desired result

\begin{equation}
    \Bigg|\sum_{j=m+1}^{n} x_j y_j \Bigg| \leq 2M|y_{m+1}|
\end{equation}

Since $y_n \rightarrow 0$, we can argue that for all $m \geq N$, 

\begin{equation}
    | y_m | < \frac{\epsilon}{2M}
\end{equation}

Notice how in (18), the right-hand side is independent of the choice of n. Thus, the inequality becomes

\begin{equation}
\begin{split}
    &\Bigg|\sum_{j=m+1}^{n} x_j y_j \Bigg| \leq 2M(\frac{\epsilon}{2M}) = \epsilon
\end{split}
\end{equation}

Let $S_n$ represent the $n^{th}$ partial sum of the entire series. Thus, we have shown that for all $n, m \geq N$, $|S_n - S_m| < \epsilon$. Therefore, the sequence of partial sums is Cauchy, and the series converges.  

\end{document}
